{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea237923-896b-4176-a3ae-97d0671c8d38",
   "metadata": {},
   "source": [
    "## Creating 4LAC for AGN Pop - version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302855be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from astropy.table import QTable, Table\n",
    "import astropy.units as u\n",
    "from astropy.io import ascii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d04a16",
   "metadata": {},
   "source": [
    "First set the paths of the catalog files. Note here I'm using the DR2 catalogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e127ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_4fgl_dr2_catalog = 'input_catalogs/gll_psc_v27.fit'\n",
    "path_4lac_low_gal_lat = 'input_catalogs/table-4LAC-DR2-l.fits'\n",
    "path_4lac_high_gal_lat = 'input_catalogs/table-4LAC-DR2-h.fits'\n",
    "# Paolo Goldoni's catalog (revised 4LAC redshifts) version 2: https://zenodo.org/record/5512660#.YVcoKHuxXRY \n",
    "path_goldoni_catalog = 'input_catalogs/4LAC_newz_AGNPop_2021.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1571f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_4fgl_dr2():\n",
    "    hdulist = fits.open(path_4fgl_dr2_catalog)\n",
    "    ptSrcCat = hdulist[1].data\n",
    "    for i, name in enumerate(ptSrcCat['Source_Name']):\n",
    "        name = name.replace(\"4FGL \", \"\")\n",
    "        name = name.replace(\" \", \"\")\n",
    "        if name.endswith('c'):\n",
    "            name = name.replace('c', '')\n",
    "        ptSrcCat['Source_Name'][i] = name\n",
    "    return ptSrcCat\n",
    "\n",
    "def read_4lac_catalog_names(filename):\n",
    "    hdulist = fits.open(filename)\n",
    "    ptSrcCat = hdulist[1].data\n",
    "    names = ptSrcCat['Source_Name']\n",
    "    sed_class = ptSrcCat['SED_class']\n",
    "    redshifts = ptSrcCat['Redshift']\n",
    "    for i, name in enumerate(names):\n",
    "        name = name.replace(\"4FGL \", \"\")\n",
    "        name = name.replace(\" \", \"\")\n",
    "        names[i] = name.replace('c', '')\n",
    "    return QTable([names, redshifts, sed_class], names=('Source_Name', 'Redshift', 'SED_class'))\n",
    "\n",
    "def read_goldoni_catalog():\n",
    "    hdulist = fits.open(path_goldoni_catalog)\n",
    "    goldoni = hdulist[1].data\n",
    "    names = goldoni['4FGL name']\n",
    "    for i, name in enumerate(names):\n",
    "        names[i] = name.replace(\"4FGL\",\"\")\n",
    "        if \"J0947.1-25\" in name:\n",
    "            names[i] = \"J0947.1-2541\"\n",
    "    goldoni['4FGL name'] = names\n",
    "    return goldoni\n",
    "\n",
    "def merge_4lac_and_4fgl():\n",
    "    four_fgl = read_4fgl_dr2()\n",
    "    four_lac_l = read_4lac_catalog_names(path_4lac_low_gal_lat)\n",
    "    four_lac_h = read_4lac_catalog_names(path_4lac_high_gal_lat)\n",
    "\n",
    "    mask_4lac = np.zeros(np.shape(four_fgl['Source_Name']), dtype=bool)\n",
    "    # mask_4lac = mask_4lac*False\n",
    "    for i, name in enumerate(four_fgl['Source_Name']):\n",
    "        if name in four_lac_l['Source_Name']:\n",
    "            mask_4lac[i] = True\n",
    "        elif name in four_lac_h['Source_Name']:\n",
    "            mask_4lac[i] = True\n",
    "    lac_fgl_crosscatalog = QTable(four_fgl[mask_4lac])\n",
    "\n",
    "    print(\"Total number of 4LAC entries found in the 4FGL: {}\".format(len(lac_fgl_crosscatalog)))\n",
    "    print(\"Total number of 4LAC entries: {}\".format(len(four_lac_l)+len(four_lac_h)))\n",
    "    \n",
    "    # Create new column in the 4fgl\n",
    "    lac_fgl_crosscatalog['Redshift'] = -1.\n",
    "    redshifts_added = 0\n",
    "    pos_redshifts_added = 0\n",
    "    for i, name in enumerate(lac_fgl_crosscatalog['Source_Name']):\n",
    "        if name in four_lac_l['Source_Name']:\n",
    "            lac_fgl_crosscatalog['Redshift'][i] = four_lac_l['Redshift'][four_lac_l['Source_Name'] == name]\n",
    "            redshifts_added += 1\n",
    "            if four_lac_l['Redshift'][four_lac_l['Source_Name'] == name] > 0:\n",
    "                pos_redshifts_added += 1\n",
    "        elif name in four_lac_h['Source_Name']:\n",
    "            lac_fgl_crosscatalog['Redshift'][i] = four_lac_h['Redshift'][four_lac_h['Source_Name'] == name]\n",
    "            redshifts_added += 1\n",
    "            if four_lac_h['Redshift'][four_lac_h['Source_Name'] == name] > 0:\n",
    "                pos_redshifts_added += 1\n",
    "        else:\n",
    "            print(\"This source did not appear in neither of the 4LAC catalogs...\")\n",
    "    print(\"Added a total of {} redshifts. {} had positive values.\".format(redshifts_added, pos_redshifts_added))\n",
    "    return lac_fgl_crosscatalog\n",
    "\n",
    "def add_sed_class_to_merged_4fgl_and_4lac():\n",
    "    catalog = merge_4lac_and_4fgl()\n",
    "    four_lac_l = read_4lac_catalog_names(path_4lac_low_gal_lat)\n",
    "    four_lac_h = read_4lac_catalog_names(path_4lac_high_gal_lat)\n",
    "\n",
    "    sed_class = []\n",
    "    for source_name in catalog['Source_Name']:\n",
    "        if source_name in four_lac_l['Source_Name']:\n",
    "            sed_class.append(four_lac_l['SED_class'][four_lac_l['Source_Name'] == source_name][0])\n",
    "        elif source_name in four_lac_h['Source_Name']:\n",
    "            sed_class.append(four_lac_h['SED_class'][four_lac_h['Source_Name'] == source_name][0])\n",
    "    catalog['SED_class'] = sed_class\n",
    "    return catalog\n",
    "    \n",
    "def goldoni_revised_4lac():\n",
    "    catalog = add_sed_class_to_merged_4fgl_and_4lac()\n",
    "    goldoni = read_goldoni_catalog()\n",
    "    # Create some variables to store statistics:\n",
    "    valid_redshifts = 0\n",
    "    removed_valid_redshift = 0\n",
    "    added_valid_redshift = 0\n",
    "    updated_value = 0\n",
    "    for i, name in enumerate(catalog['Source_Name']):\n",
    "        if name in goldoni['4FGL name']:\n",
    "#             goldoni_redshift = goldoni['Redshift'][goldoni['4FGL name'] == name][0]\n",
    "            goldoni_redshift = goldoni['Redshift_corr'][goldoni['4FGL name'] == name][0]\n",
    "#             print(\"Updating redshift value, from {:2.3f} to {:2.3f}\".format(catalog['Redshift'][i], goldoni_redshift))\n",
    "            if \"{:2.3f}\".format(catalog['Redshift'][i]) == \"{:2.6f}\".format(goldoni_redshift):\n",
    "                valid_redshifts += 1\n",
    "            elif catalog['Redshift'][i] > 0. and goldoni_redshift > 0.:\n",
    "                updated_value += 1\n",
    "            elif catalog['Redshift'][i] < 0. and goldoni_redshift > 0.:\n",
    "                added_valid_redshift += 1\n",
    "            elif catalog['Redshift'][i] > 0. and goldoni_redshift < 0.:\n",
    "                removed_valid_redshift += 1\n",
    "            catalog['Redshift'][i] = \"{:2.6f}\".format(goldoni_redshift)\n",
    "        else:\n",
    "            catalog['Redshift'][i] = \"{:2.6f}\".format(catalog['Redshift'][i])\n",
    "#         else:\n",
    "#             print(\"{} in P. Goldoni catalog, but not within 4LAC.\".format(name))\n",
    "    print(\" -- From Paolo's catalog -- \")\n",
    "    print(\"A total of {} redshifts were correct within 4LAC\".format(valid_redshifts))\n",
    "    print(\"Removed a total of {} redshifts from 4LAC\".format(removed_valid_redshift))\n",
    "    print(\"Added a total of {} redshifts to 4LAC\".format(added_valid_redshift))\n",
    "    print(\"Updated a total of {} redshifts of 4LAC\".format(updated_value))\n",
    "    return catalog\n",
    "\n",
    "def convert_PLSuperExpCutoff_entries_to_LogParabola(catalog):\n",
    "    for i, entry in enumerate(catalog):\n",
    "        if entry['SpectrumType'] == 'PLSuperExpCutoff ':\n",
    "            catalog['SpectrumType'][i] = 'LogParabola      '\n",
    "    return catalog\n",
    "    \n",
    "\n",
    "def create_agn_pop_shared_4lac_catalog():\n",
    "    catalog = goldoni_revised_4lac()\n",
    "    keep_columns = ['Source_Name', 'RAJ2000', 'DEJ2000', 'Redshift', 'SpectrumType', 'Pivot_Energy', \n",
    "                    'PL_Flux_Density', 'PL_Index', 'LP_Flux_Density', 'LP_Index', 'LP_beta', 'SED_class', \n",
    "                    'Variability_Index', 'Frac_Variability', 'Unc_Frac_Variability', 'Flux1000', 'Unc_Flux1000', 'Flux_History', 'Unc_Flux_History']\n",
    "    new_catalog = QTable()\n",
    "    for column in keep_columns:\n",
    "        new_catalog[column] = catalog[column]\n",
    "    final_catalog = convert_PLSuperExpCutoff_entries_to_LogParabola(catalog[keep_columns])\n",
    "    return final_catalog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0946c",
   "metadata": {},
   "source": [
    "Generate the catalog and store it in a couple of different formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f212767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 4LAC entries found in the 4FGL: 3511\n",
      "Total number of 4LAC entries: 3511\n",
      "Added a total of 3511 redshifts. 1767 had positive values.\n",
      " -- From Paolo's catalog -- \n",
      "A total of 0 redshifts were correct within 4LAC\n",
      "Removed a total of 87 redshifts from 4LAC\n",
      "Added a total of 23 redshifts to 4LAC\n",
      "Updated a total of 236 redshifts of 4LAC\n"
     ]
    }
   ],
   "source": [
    "agn_pop_catalog = create_agn_pop_shared_4lac_catalog()\n",
    "# ascii.write(agn_pop_catalog, 'resulting_catalogs/agn_pop_4lac_dr2.dat', overwrite=True)  \n",
    "agn_pop_catalog.write('resulting_catalogs/agn_pop_4lac_dr2.ecsv', overwrite=True)  \n",
    "agn_pop_catalog.write('resulting_catalogs/agn_pop_4lac_dr2.fits', overwrite=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b01193",
   "metadata": {},
   "source": [
    "Only selecting those sources with a valid redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370c9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_with_redshift = agn_pop_catalog[agn_pop_catalog['Redshift'] > 0.]\n",
    "# ascii.write(sources_with_redshift, 'resulting_catalogs/agn_pop_4lac_dr2_with_z.dat', overwrite=True)  \n",
    "sources_with_redshift.write('resulting_catalogs/agn_pop_4lac_dr2_with_z.ecsv', overwrite=True)  \n",
    "sources_with_redshift.write('resulting_catalogs/agn_pop_4lac_dr2_with_z.fits', overwrite=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc94ada0-7448-4012-a0ac-d4e774f9e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources_with_redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173144bf",
   "metadata": {},
   "source": [
    "We want to analyze all of the sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70535adb-57e2-4047-b911-afc31d8e8c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>QTable length=3511</i>\n",
       "<table id=\"table140168283192576\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>Source_Name</th><th>RAJ2000</th><th>DEJ2000</th><th>Redshift</th><th>SpectrumType</th><th>Pivot_Energy</th><th>PL_Flux_Density</th><th>PL_Index</th><th>LP_Flux_Density</th><th>LP_Index</th><th>LP_beta</th><th>SED_class</th><th>Variability_Index</th><th>Frac_Variability</th><th>Unc_Frac_Variability</th><th>Flux1000</th><th>Unc_Flux1000</th><th>Flux_History</th><th>Unc_Flux_History</th></tr></thead>\n",
       "<thead><tr><th>str18</th><th>float32</th><th>float32</th><th>float64</th><th>str17</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>str3</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32[10]</th><th>float32[10,2]</th></tr></thead>\n",
       "<tr><td>J0001.2+4741</td><td>0.3126</td><td>47.6859</td><td>-inf</td><td>PowerLaw</td><td>2514.9417</td><td>1.9206343e-14</td><td>2.2221549</td><td>1.893531e-14</td><td>2.2337143</td><td>-0.008456561</td><td>ISP</td><td>20.01873</td><td>0.69284904</td><td>0.40699458</td><td>1.2159239e-10</td><td>3.2066936e-11</td><td>3.2381073e-09 .. 3.748821e-13</td><td>-1.7942571e-09 .. 1.8192396e-09</td></tr>\n",
       "<tr><td>J0001.2-0747</td><td>0.3151</td><td>-7.7971</td><td>-inf</td><td>PowerLaw</td><td>1612.6141</td><td>3.3465656e-13</td><td>2.1049428</td><td>3.5833494e-13</td><td>2.0718932</td><td>0.04876986</td><td>LSP</td><td>33.22868</td><td>0.33279318</td><td>0.108399756</td><td>8.2320506e-10</td><td>5.6777423e-11</td><td>9.068161e-09 .. 5.3190576e-09</td><td>-1.6483049e-09 .. 1.8038276e-09</td></tr>\n",
       "<tr><td>J0001.5+2113</td><td>0.3815</td><td>21.2183</td><td>1.106</td><td>LogParabola</td><td>355.78442</td><td>3.9051106e-11</td><td>2.659308</td><td>4.532746e-11</td><td>2.5481505</td><td>0.15877607</td><td>ISP</td><td>1564.4176</td><td>1.0545832</td><td>0.24980173</td><td>1.3590526e-09</td><td>6.8598856e-11</td><td>3.5381675e-09 .. 1.9309729e-07</td><td>-2.7883742e-09 .. 7.1862325e-09</td></tr>\n",
       "<tr><td>J0001.6-4156</td><td>0.4165</td><td>-41.9425</td><td>-inf</td><td>PowerLaw</td><td>4009.3838</td><td>2.0757042e-14</td><td>1.7558894</td><td>2.3474046e-14</td><td>1.6675872</td><td>0.06975478</td><td>HSP</td><td>16.148964</td><td>0.32796606</td><td>0.17213507</td><td>3.0486913e-10</td><td>3.4296448e-11</td><td>2.4941327e-09 .. 2.257481e-09</td><td>-7.192918e-10 .. 6.9632494e-10</td></tr>\n",
       "<tr><td>J0002.1-6728</td><td>0.5378</td><td>-67.4746</td><td>-inf</td><td>PowerLaw</td><td>3689.1895</td><td>1.8744873e-14</td><td>1.846469</td><td>2.3711413e-14</td><td>1.6778738</td><td>0.16372891</td><td></td><td>13.479138</td><td>0.30663496</td><td>0.19210596</td><td>2.4168523e-10</td><td>3.0690155e-11</td><td>1.7362627e-09 .. 2.0357045e-09</td><td>-6.762483e-10 .. 7.001091e-10</td></tr>\n",
       "<tr><td>J0002.3-0815</td><td>0.5937</td><td>-8.2652</td><td>-inf</td><td>PowerLaw</td><td>3959.9126</td><td>7.564005e-15</td><td>1.9895958</td><td>9.510118e-15</td><td>1.9282347</td><td>0.15012589</td><td>LSP</td><td>11.524589</td><td>0.31231728</td><td>0.72063845</td><td>1.1693464e-10</td><td>3.32925e-11</td><td>7.317083e-12 .. 1.5915405e-09</td><td>nan .. 1.2170501e-09</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>J2359.0+3922</td><td>359.7548</td><td>39.3669</td><td>1.198</td><td>PowerLaw</td><td>1621.9188</td><td>1.1973475e-13</td><td>2.3477888</td><td>1.1708454e-13</td><td>2.3640099</td><td>-0.017356092</td><td>LSP</td><td>38.971645</td><td>0.8606212</td><td>0.25553405</td><td>2.7603766e-10</td><td>4.0250227e-11</td><td>4.2458934e-09 .. 1.6776674e-08</td><td>-2.135404e-09 .. 3.4258993e-09</td></tr>\n",
       "<tr><td>J2359.0-3038</td><td>359.7719</td><td>-30.6367</td><td>0.165</td><td>PowerLaw</td><td>3703.5862</td><td>3.3936805e-14</td><td>1.8187637</td><td>3.5061916e-14</td><td>1.7988403</td><td>0.017256342</td><td>HSP</td><td>11.602486</td><td>0.15399826</td><td>0.17869046</td><td>4.3815906e-10</td><td>4.2386882e-11</td><td>4.8273003e-09 .. 1.6648541e-09</td><td>-1.0239388e-09 .. 7.973747e-10</td></tr>\n",
       "<tr><td>J2359.1+1719</td><td>359.7756</td><td>17.3225</td><td>-inf</td><td>PowerLaw</td><td>2801.7244</td><td>1.7541105e-14</td><td>2.0055103</td><td>2.2782769e-14</td><td>1.9000158</td><td>0.16625412</td><td>ISP</td><td>9.186948</td><td>0.0</td><td>10.0</td><td>1.3639893e-10</td><td>3.0394815e-11</td><td>7.771902e-10 .. 4.3490941e-10</td><td>-6.846583e-10 .. 1.0321224e-09</td></tr>\n",
       "<tr><td>J2359.2-3134</td><td>359.8167</td><td>-31.5832</td><td>0.99</td><td>PowerLaw</td><td>663.0757</td><td>8.154589e-13</td><td>2.604698</td><td>8.583684e-13</td><td>2.5858138</td><td>0.039058067</td><td>LSP</td><td>85.624756</td><td>1.2248484</td><td>0.32078165</td><td>1.7424803e-10</td><td>2.969267e-11</td><td>1.0777564e-09 .. 5.405605e-12</td><td>nan .. 2.3832092e-09</td></tr>\n",
       "<tr><td>J2359.3+0215</td><td>359.8329</td><td>2.2603</td><td>-inf</td><td>PowerLaw</td><td>4726.44</td><td>5.183745e-15</td><td>1.7947075</td><td>9.2811314e-15</td><td>1.607395</td><td>0.42203328</td><td>LSP</td><td>13.478229</td><td>0.3452614</td><td>0.969457</td><td>1.0321737e-10</td><td>2.7625228e-11</td><td>1.061645e-09 .. 2.4759987e-09</td><td>-4.592819e-10 .. 9.719748e-10</td></tr>\n",
       "<tr><td>J2359.3-2049</td><td>359.8357</td><td>-20.8189</td><td>0.096</td><td>PowerLaw</td><td>1965.9421</td><td>8.613323e-14</td><td>2.0880377</td><td>8.2531455e-14</td><td>2.1214917</td><td>-0.026858702</td><td>LSP</td><td>11.05288</td><td>0.12375273</td><td>0.24667947</td><td>3.2262729e-10</td><td>3.6377887e-11</td><td>4.3693253e-09 .. 3.524929e-09</td><td>-1.3597997e-09 .. 1.5734642e-09</td></tr>\n",
       "<tr><td>J2359.9-3736</td><td>359.9816</td><td>-37.616</td><td>-inf</td><td>PowerLaw</td><td>1844.0975</td><td>5.4040583e-14</td><td>2.0688875</td><td>7.380662e-14</td><td>1.9067892</td><td>0.25992045</td><td>LSP</td><td>7.181523</td><td>0.0</td><td>10.0</td><td>1.7806581e-10</td><td>2.820794e-11</td><td>3.2138203e-09 .. 7.503538e-10</td><td>-1.2280752e-09 .. 1.029837e-09</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<QTable length=3511>\n",
       "Source_Name  RAJ2000  ...         Unc_Flux_History       \n",
       "   str18     float32  ...          float32[10,2]         \n",
       "------------ -------- ... -------------------------------\n",
       "J0001.2+4741   0.3126 ... -1.7942571e-09 .. 1.8192396e-09\n",
       "J0001.2-0747   0.3151 ... -1.6483049e-09 .. 1.8038276e-09\n",
       "J0001.5+2113   0.3815 ... -2.7883742e-09 .. 7.1862325e-09\n",
       "J0001.6-4156   0.4165 ...  -7.192918e-10 .. 6.9632494e-10\n",
       "J0002.1-6728   0.5378 ...   -6.762483e-10 .. 7.001091e-10\n",
       "J0002.3-0815   0.5937 ...            nan .. 1.2170501e-09\n",
       "         ...      ... ...                             ...\n",
       "J2359.0+3922 359.7548 ...  -2.135404e-09 .. 3.4258993e-09\n",
       "J2359.0-3038 359.7719 ...  -1.0239388e-09 .. 7.973747e-10\n",
       "J2359.1+1719 359.7756 ...  -6.846583e-10 .. 1.0321224e-09\n",
       "J2359.2-3134 359.8167 ...            nan .. 2.3832092e-09\n",
       "J2359.3+0215 359.8329 ...   -4.592819e-10 .. 9.719748e-10\n",
       "J2359.3-2049 359.8357 ... -1.3597997e-09 .. 1.5734642e-09\n",
       "J2359.9-3736 359.9816 ...  -1.2280752e-09 .. 1.029837e-09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agn_pop_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59baf9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485cf2d3-71b5-4b2d-904b-98c879b331d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = fits.open(path_4lac_high_gal_lat)\n",
    "th = Table(fh[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89411e5-f635-405b-a44b-022f14ddd147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67890532-464c-4688-ad9c-463c0dba8864",
   "metadata": {},
   "source": [
    "Filtering only the columns we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff70a6df-b176-442b-b298-ed713b7ebc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "List of column names: agn_pop_catalog\n",
      "\n",
      " ['Source_Name', 'RAJ2000', 'DEJ2000', 'Redshift', 'SpectrumType', 'Pivot_Energy', 'PL_Flux_Density', 'PL_Index', 'LP_Flux_Density', 'LP_Index', 'LP_beta', 'SED_class', 'Variability_Index', 'Frac_Variability', 'Unc_Frac_Variability', 'Flux1000', 'Unc_Flux1000', 'Flux_History', 'Unc_Flux_History']\n",
      "\n",
      "Number of table rows: 3511\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nList of column names: agn_pop_catalog\\n\\n', agn_pop_catalog.colnames)  # List of column names\n",
    "print('\\nNumber of table rows:', len(agn_pop_catalog))      # Number of table rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9e8d4-0674-4924-ac77-9e870458dbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a2aa1-eee5-4093-b597-4d2bb6a44188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c92e213-7286-4a34-ba09-b0c2b9b26a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d5463e5-7a49-4259-91d2-02f88d3270ce",
   "metadata": {},
   "source": [
    "## Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e9ed2-bf88-4d7a-867d-9f0ee7cedf31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602d528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf39a2b-186b-415b-80fc-acc358fdf369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6d0f1-4813-4859-bf88-d9365c8a7421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaacd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c413a44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cd328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed95f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e01fa617",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53692879-25e5-4923-9dab-7c17751e608d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74229aa7-ff43-4910-8cea-5339ae02f09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a384a82-9d07-4b61-9509-1300a1c50642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164199e-77fd-42ab-a615-11a44c15d1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbe63a-2ad1-466c-a6bb-b1a4216b3eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c1a63-ba0f-48ab-b070-09cc5e613fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7c303-bc29-4353-97f0-0a9ca3136b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df15ee91-d382-4f11-8740-971a57dcd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the arrays with flux information to a file\n",
    "\n",
    "# np.savez('source_flux_arrays.npz', array1=source_flux, array2=source_flux_unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5aa190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b6dbb-098a-4895-a614-47fe5e4b11ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb5ed9c-eb85-4798-89ac-62feff2fa50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9563ab-3ae4-4a1c-8c80-e265cc723053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144815e6-d66c-4c49-8bc1-f74ff82dfc63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc0e65-1229-4adb-9340-ec9f1cb30c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d246e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87a818d0",
   "metadata": {},
   "source": [
    "# Calculating F_var for all of the sources using the History Flux\n",
    "\n",
    "in which the Fractional Variability is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    F_{\\rm var} = \\sqrt{ \\frac{ S^{2} - \\overline{\\sigma_{\\rm err}^{2}} }{ F_{av}\\ ^{2} } }\n",
    "\\end{equation}\n",
    "\n",
    "and, therefore\n",
    "\n",
    "\\begin{equation}\n",
    "    F_{\\rm var} = \\sqrt{ \\frac{1}{ F_{av}\\ ^{2} } \\left [\\frac{1}{N - 1} \\sum_{i=1}^{N} \\left ( F_{i} - F_{av} \\right )^{2} - \\frac{1}{N} \\sum_{i=1}^{N} \\sigma_{\\rm err, i}^{2} \\right ] }\n",
    "\\end{equation}\n",
    "\n",
    "with an error\n",
    "\n",
    "\\begin{equation}\n",
    "    err(F_{\\rm var}) = \\sqrt{ \\left ( \\sqrt{\\frac{1}{2N}} \\frac{\\overline{\\sigma_{\\rm err}^{2}}}{F_{av}\\ ^{2} \\ F_{\\rm var}}  \\right )^{2} + \\left ( \\sqrt{\\frac{\\overline{\\sigma_{\\rm err}^{2}}}{N}} \\frac{1}{F_{av}} \\right )^{2} }\n",
    "\\end{equation}\n",
    "\n",
    "that can be rewritten as\n",
    "\n",
    "\\begin{equation}\n",
    "    F_{\\rm var}^{2} = \\sigma_{\\rm NXS}^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "    err(F_{\\rm var}) = \\sqrt{ \\left ( \\sqrt{\\frac{1}{2N}} \\frac{\\overline{\\sigma_{\\rm err}^{2}}}{F_{av}\\ ^{2}}  \\right )^{2} \\frac{1}{\\sigma_{\\rm NXS}^{2}} + \\left ( \\sqrt{\\frac{\\overline{\\sigma_{\\rm err}^{2}}}{N}} \\frac{1}{F_{av}} \\right )^{2} }\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "We have also included the condition that if $F_{\\rm var} = 0$, $err(F_{\\rm var}) = 0.1$, so it returns a real number instead of NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24c51f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## F_var without considering UL, only the flux points\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_Fvar(history_flux, flux_error):\n",
    "    ########## Description ##########\n",
    "    # ---------- Input ----------\n",
    "    # history_flux : history flux points from 4FGL                 (float)\n",
    "    # flux_error   : error of the flux value                       (1D-array)\n",
    "    # ---------- Output ----------\n",
    "    # Fvar         : Fvar of the source            (float)\n",
    "    # Fvar_error   : error of the value Fvar       (float)\n",
    "    #################################\n",
    "    \n",
    "    F_av = np.average(history_flux)  # simple average\n",
    "    n = len(history_flux)\n",
    "    \n",
    "    if n != 1:\n",
    "        s_squared = (1 / (n - 1)) * sum((F_i - F_av)**2 for F_i in history_flux)\n",
    "    else:\n",
    "        s_squared = (1 / (n)) * sum((F_i - F_av)**2 for F_i in history_flux)\n",
    "        print(f'\\nthe source has only 1 flux point selected!')\n",
    "    \n",
    "    # s_squared = (1 / (n - 1)) * sum((F_i - F_av)**2 for F_i in history_flux)\n",
    "    mse = (1/n) * sum(sigma_i**2 for sigma_i in flux_error)    \n",
    "    \n",
    "    ## Excess Variance\n",
    "    \n",
    "    excess_variance = s_squared - mse\n",
    "\n",
    "    normalized_excess_variance = excess_variance / F_av**2\n",
    "\n",
    "    term1 = np.sqrt(2/n) * ( mse / (F_av**2) )\n",
    "    term2 = np.sqrt(mse/n) * ( 2 / F_av )\n",
    "\n",
    "    unc_normalized_excess_variance = np.sqrt( (term1)**2 + ( (term2)**2 * normalized_excess_variance) )\n",
    "\n",
    "    ## Fractional Variability\n",
    "\n",
    "    frac_variability = np.sqrt( max(normalized_excess_variance, 0) )  # 4FGL paper: max(term_max, 0)\n",
    "\n",
    "    factor1 = np.sqrt( 1 / (2*n) ) * mse / ( F_av**2 )\n",
    "    factor2 = np.sqrt( mse / n ) * ( 1 / F_av )\n",
    "\n",
    "    if (frac_variability == 0):\n",
    "        unc_frac_variability = 0.1\n",
    "    else:\n",
    "        unc_frac_variability = np.sqrt( ( (factor1)**2 / normalized_excess_variance ) + (factor2)**2 )\n",
    "\n",
    "    return normalized_excess_variance, unc_normalized_excess_variance, frac_variability, unc_frac_variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad1186aa-f87b-45f5-8866-363de2d12aa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'catalog_with_flux_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m average_flux \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m unc_f_var_sources \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mcatalog_with_flux_history\u001b[49m)):\n\u001b[1;32m     12\u001b[0m     \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m## Selecting each source by name\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     select_source \u001b[38;5;241m=\u001b[39m catalog_with_flux_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource_Name\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[1;32m     15\u001b[0m     source_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselect_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'catalog_with_flux_history' is not defined"
     ]
    }
   ],
   "source": [
    "## Calculating F_var for each source\n",
    "\n",
    "source_names = []\n",
    "f_var_sources = []\n",
    "source_has_UL = []\n",
    "average_flux = []\n",
    "\n",
    "unc_f_var_sources = []\n",
    "\n",
    "\n",
    "for i in range(len(catalog_with_flux_history)):\n",
    "    \n",
    "    ## Selecting each source by name\n",
    "    select_source = catalog_with_flux_history['Source_Name'][i]\n",
    "    source_names.append(f'{select_source}')\n",
    "    \n",
    "    ## Selecting the dataframe of the selected source\n",
    "    source_df = catalog_with_flux_history[catalog_with_flux_history['Source_Name'] == f'{select_source}']\n",
    "\n",
    "    source_flux_history = source_df['Flux_History'][0][:]\n",
    "    source_unc_flux = source_df['Unc_Flux_History'][0][:]\n",
    "    \n",
    "    ## Creating a mask for upper limits\n",
    "    mask_this_source = np.invert(np.isnan(source_df['Unc_Flux_History'][0][:,0]))\n",
    "\n",
    "    ## Selecting the values that are not Upper Limits\n",
    "    source_flux_history = source_df['Flux_History'][0][mask_this_source]\n",
    "\n",
    "    ## Choose the positive uncertainties (seems larger)\n",
    "    source_unc_flux = source_df['Unc_Flux_History'][0][:,1][mask_this_source]\n",
    "    \n",
    "    if (len(source_flux_history) == 10):\n",
    "        source_has_UL.append(False)\n",
    "    else:\n",
    "        source_has_UL.append(True)\n",
    "\n",
    "    average_flux.append(np.average(source_flux_history))\n",
    "    \n",
    "    sigma_nxs, unc_sigma_nxs, fvar_source, unc_fvar_source = calculate_Fvar(source_flux_history, source_unc_flux)\n",
    "    f_var_sources.append(fvar_source)\n",
    "    unc_f_var_sources.append(unc_fvar_source)\n",
    "    \n",
    "    \n",
    "# print(source_names)\n",
    "# print(source_has_UL)\n",
    "# print(f_var_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58330b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(source_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a70543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fvar_Luana = pd.DataFrame({'Source_Name': source_names, 'Frac_Variability': f_var_sources,\n",
    "                           'Unc_Frac_Variability': unc_f_var_sources, 'Upper_limits': source_has_UL})\n",
    "\n",
    "fvar_Luana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48272c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_with_fvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6a0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9984d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fvar 4FGL vs. Luana\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "## Get the color values for the markers based on the Upper_limits column\n",
    "colors = ['gray' if ul else 'blue' for ul in fvar_Luana['Upper_limits']]\n",
    "\n",
    "plt.scatter(fvar_Luana['Frac_Variability'], catalog_with_fvar['Frac_Variability'], marker='.', c=colors)\n",
    "\n",
    "plt.xlabel('Fvar (Luana)', fontsize=15)\n",
    "plt.ylabel('Fvar (4FGL)', fontsize=15)  ## with Flux_History points\n",
    "plt.title('Fvar of 4FGL sources in a Year Cadence (masking ULs)', fontsize=18)\n",
    "# plt.legend()\n",
    "\n",
    "legend_labels = ['w/o Upper Limits', 'w/ Upper Limits']\n",
    "legend_handles = [plt.scatter([], [], color='blue', marker='.'), plt.scatter([], [], color='gray', marker='.')]\n",
    "plt.legend(legend_handles, legend_labels, loc='upper right', fontsize=15)\n",
    "\n",
    "plt.xlim(0,2.5)\n",
    "plt.ylim(0,2.5)\n",
    "\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e471e5-2fd0-4688-be74-357925036d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of Fvar(4FGL) vs average spectrum flux + Fvar(Luana) vs average history flux\n",
    "\n",
    "## 4FGL\n",
    "x1 = average_flux\n",
    "y1 = catalog_with_fvar['Frac_Variability']\n",
    "\n",
    "## Luana\n",
    "x2 = average_flux\n",
    "y2 = fvar_Luana['Frac_Variability']\n",
    "\n",
    "## Get the color values for the markers based on the Upper_limits column\n",
    "colors1 = ['lightgray' if ul else 'red' for ul in fvar_Luana['Upper_limits']]\n",
    "colors2 = ['gray' if ul else 'blue' for ul in fvar_Luana['Upper_limits']]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.scatter(x1, y1, label='4FGL', marker='.', c=colors1, s=50)\n",
    "plt.scatter(x2, y2, label='Luana', marker='.', c=colors2, s=50)\n",
    "plt.title('Comparison of Fvar calculations vs. Average of History Flux (Year Cadence)', fontsize=18)\n",
    "plt.xlabel('Average History Flux (Photon Flux (0.1-100 GeV ph $cm^{-2}$ $s^{-1}$))', fontsize=15)\n",
    "plt.ylabel('Fvar', fontsize=15)\n",
    "\n",
    "legend_labels = ['w/o UL - 4FGL', 'w/ UL - 4FGL', 'w/o UL - Luana', 'w/ UL - Luana']\n",
    "legend_handles = [plt.scatter([], [], color='red', marker='.'), plt.scatter([], [], color='lightgray', marker='.'),\n",
    "                 plt.scatter([], [], color='blue', marker='.'), plt.scatter([], [], color='gray', marker='.')]\n",
    "plt.legend(legend_handles, legend_labels, loc='upper right', fontsize=15)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed1cf7-3409-40df-8a20-13c39d874b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800b072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_averaging_catalog_errors(catalog):\n",
    "    all_fluxes = []\n",
    "    all_flux_uncs = []\n",
    "    for entry in catalog:\n",
    "        fluxes = entry[\"Flux_History\"]\n",
    "        fluxes_unc = entry[\"Unc_Flux_History\"][:, 1].copy()\n",
    "        errors = catalog[\"Unc_Flux_History\"][0][:]\n",
    "        nan_locations = np.where(np.isnan(errors[:,0]))[0]\n",
    "        for i, err in enumerate(errors):\n",
    "            if i not in nan_locations:\n",
    "#                 print(err)\n",
    "                \n",
    "                ## Average of errors\n",
    "#                 fluxes_unc[i] = np.average(np.abs(err), axis=0)\n",
    "\n",
    "                ## Minimum of errors\n",
    "#                 fluxes_unc[i] = np.min(np.abs(err), axis=0)\n",
    "\n",
    "                ## Maximum of errors\n",
    "                fluxes_unc[i] = np.max(np.abs(err), axis=0)\n",
    "#                 print(fluxes_unc[i])\n",
    "            \n",
    "        all_fluxes.append(fluxes)\n",
    "        all_flux_uncs.append(fluxes_unc)\n",
    "    return all_fluxes, all_flux_uncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c62b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_with_average = test_averaging_catalog_errors(catalog_with_flux_history)\n",
    "\n",
    "# catalog_with_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog_with_average[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33255d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog_with_average[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f5abd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating F_var for each source\n",
    "\n",
    "source_names_4FGL = []\n",
    "source_has_UL_4FGL = []\n",
    "\n",
    "## Masking Upper Limits\n",
    "f_var_4FGL_no_UL = []\n",
    "f_var_unc_4FGL_no_UL = []\n",
    "average_flux_4FGL_no_UL = []\n",
    "\n",
    "## Keeping UL and selecting the higher uncertainty\n",
    "f_var_4FGL_w_UL = []\n",
    "f_var_unc_4FGL_w_UL = []\n",
    "average_flux_4FGL_w_UL = []\n",
    "\n",
    "catalog_with_average = test_averaging_catalog_errors(catalog_with_flux_history)\n",
    "\n",
    "\n",
    "for i in range(len(catalog_with_flux_history)):\n",
    "    \n",
    "    ## Selecting each source by name\n",
    "    select_source = catalog_with_flux_history['Source_Name'][i]\n",
    "    source_names_4FGL.append(f'{select_source}')\n",
    "    \n",
    "    ## Selecting the dataframe of the selected source\n",
    "    source_df = catalog_with_flux_history[catalog_with_flux_history['Source_Name'] == f'{select_source}']\n",
    "\n",
    "    ## Defining Flux Points and Uncertainties\n",
    "    source_flux_history = source_df['Flux_History'][0][:]\n",
    "    source_unc_flux = source_df['Unc_Flux_History'][0][:]\n",
    "    \n",
    "    ## True or False for ULs\n",
    "    any_nan = np.isnan(source_df['Unc_Flux_History'][0][:,0])\n",
    "    if any(any_nan):\n",
    "        source_has_UL_4FGL.append(True) \n",
    "    else:\n",
    "        source_has_UL_4FGL.append(False)\n",
    "        \n",
    "    \n",
    "    ## Masking Upper Limits\n",
    "    \n",
    "    ## Creating a mask for upper limits\n",
    "    mask_this_source = np.invert(np.isnan(source_df['Unc_Flux_History'][0][:,0]))\n",
    "    ## Selecting the values that are not Upper Limits\n",
    "    source_flux_history_no_UL = source_df['Flux_History'][0][mask_this_source]\n",
    "    ## Choose the positive uncertainties (seems larger)\n",
    "    source_unc_flux_no_UL = source_df['Unc_Flux_History'][0][:,1][mask_this_source]\n",
    "    \n",
    "        \n",
    "    ## Keeping UL and selecting the higher uncertainty\n",
    "    source_flux_history_w_UL = source_flux_history\n",
    "    source_unc_flux_w_UL = source_df['Unc_Flux_History'][0][:,1]\n",
    "    \n",
    "    \n",
    "    #### Averaging Error ###\n",
    "#     source_flux_history = catalog_with_average[0][i]\n",
    "#     source_unc_flux = catalog_with_average[1][i]\n",
    "    ########################\n",
    "    \n",
    "    \n",
    "    ## Masking Upper Limits\n",
    "    sigma_nxs_no_UL, unc_sigma_nxs_no_UL, fvar_source_no_UL, fvar_unc_source_no_UL = calculate_Fvar(source_flux_history_no_UL, source_unc_flux_no_UL)\n",
    "    \n",
    "    f_var_4FGL_no_UL.append(fvar_source_no_UL)\n",
    "    f_var_unc_4FGL_no_UL.append(fvar_unc_source_no_UL)\n",
    "    average_flux_4FGL_no_UL.append(np.average(source_unc_flux_no_UL))\n",
    "\n",
    "    \n",
    "    ## Keeping UL and selecting the higher uncertainty\n",
    "    sigma_nxs_w_UL, unc_sigma_nxs_w_UL, fvar_source_w_UL, fvar_unc_source_w_UL = calculate_Fvar(source_flux_history_w_UL, source_unc_flux_w_UL)\n",
    "    \n",
    "    f_var_4FGL_w_UL.append(fvar_source_w_UL)\n",
    "    f_var_unc_4FGL_w_UL.append(fvar_unc_source_w_UL)\n",
    "    average_flux_4FGL_w_UL.append(np.average(source_flux_history_w_UL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22725d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(source_names_4FGL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8500e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_var_4FGL_no_UL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58687b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_var_4FGL_w_UL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20411544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save the arrays with F_var information to a file\n",
    "\n",
    "# ## Masking Upper Limits\n",
    "# np.savez('Fvar_year_no_UL.npz', array1=source_names_4FGL, array2=f_var_4FGL_no_UL, array3=f_var_unc_4FGL_no_UL, array4=average_flux_4FGL_no_UL)\n",
    "\n",
    "# ## Keeping UL and selecting the higher uncertainty\n",
    "# np.savez('Fvar_year_w_UL.npz', array1=source_names_4FGL, array2=f_var_4FGL_w_UL, array3=f_var_unc_4FGL_w_UL, array4=average_flux_4FGL_w_UL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845d6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The sources with UL values (small ones) - taking the higher uncertainty\n",
    "\n",
    "fvar_Luana_4FGL = pd.DataFrame({'Source_Name': source_names_4FGL, 'Frac_Variability': f_var_4FGL_w_UL,\n",
    "                                'Unc_Frac_Variability': f_var_unc_4FGL_w_UL, 'Upper_limits': source_has_UL_4FGL})\n",
    "\n",
    "fvar_Luana_4FGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_with_fvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = catalog_with_fvar['Unc_Frac_Variability'] == 10\n",
    "\n",
    "# catalog_with_fvar[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2145b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fvar 4FGL vs. Luana\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "######## with UL ########\n",
    "## Get the color values for the markers based on the Upper_limits column\n",
    "colors = ['gray' if ul else 'blue' for ul in fvar_Luana_4FGL['Upper_limits']]\n",
    "plt.scatter(fvar_Luana_4FGL['Frac_Variability'], catalog_with_fvar['Frac_Variability'], marker='.', c=colors)\n",
    "#########################\n",
    "\n",
    "\n",
    "######### no UL #########\n",
    "# plt.scatter(fvar_Luana_4FGL['Frac_Variability'], catalog_with_fvar['Frac_Variability'], marker='.')\n",
    "#########################\n",
    "\n",
    "plt.xlabel('Fvar (Luana)', fontsize=15) ## with Flux_History points\n",
    "plt.ylabel('Fvar (4FGL)', fontsize=15)\n",
    "plt.title('Year Cadence: Flux History w/ Flux$_{UL} \\sim 0$, taking higher uncertainty', fontsize=18)\n",
    "\n",
    "legend_labels = ['w/o Upper Limits', 'w/ Upper Limits']\n",
    "legend_handles = [plt.scatter([], [], color='blue', marker='.'), plt.scatter([], [], color='gray', marker='.')]\n",
    "plt.legend(legend_handles, legend_labels, loc='upper right', fontsize=15)\n",
    "\n",
    "# plt.xlim(0,2.5)\n",
    "# plt.ylim(0,2.5)\n",
    "\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ce272",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fvar 4FGL vs. Luana\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Get the color values for the markers based on the Upper_limits column\n",
    "colors = ['gray' if ul else 'blue' for ul in fvar_Luana_4FGL['Upper_limits']]\n",
    "plt.scatter(fvar_Luana_4FGL['Unc_Frac_Variability'], catalog_with_fvar['Unc_Frac_Variability'], marker='.', c=colors)\n",
    "\n",
    "plt.xlabel('Fvar Error (Luana)', fontsize=15)\n",
    "plt.ylabel('Fvar Error (4FGL)', fontsize=15)  ## with Flux_History points\n",
    "plt.title('Comparison of Uncertainties for 4FGL Fvar', fontsize=18)\n",
    "\n",
    "legend_labels = ['w/o Upper Limits', 'w/ Upper Limits']\n",
    "legend_handles = [plt.scatter([], [], color='blue', marker='.'), plt.scatter([], [], color='gray', marker='.')]\n",
    "plt.legend(legend_handles, legend_labels, loc='upper right', fontsize=15)\n",
    "\n",
    "plt.xlim(0,1.2)\n",
    "plt.ylim(0,1.2)\n",
    "\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f299db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of Fvar(4FGL) vs average spectrum flux + Fvar(Luana) vs average history flux\n",
    "\n",
    "## 4FGL\n",
    "x1 = average_flux_4FGL_w_UL\n",
    "y1 = catalog_with_fvar['Frac_Variability']\n",
    "\n",
    "## Luana\n",
    "x2 = average_flux_4FGL_w_UL\n",
    "y2 = fvar_Luana_4FGL['Frac_Variability']\n",
    "\n",
    "## Get the color values for the markers based on the Upper_limits column\n",
    "colors1 = ['lightgray' if ul else 'red' for ul in fvar_Luana_4FGL['Upper_limits']]\n",
    "colors2 = ['gray' if ul else 'blue' for ul in fvar_Luana_4FGL['Upper_limits']]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.scatter(x1, y1, marker='.', c=colors1, s=50, label='4FGL')\n",
    "plt.scatter(x2, y2, marker='.', c=colors2, s=50, label='Luana')\n",
    "plt.title('Comparison of 4FGL Fvar calculations vs. Average History Flux (Year Cadence)', fontsize=18)\n",
    "plt.xlabel('Average History Flux (Photon Flux (0.1-100 GeV ph $cm^{-2}$ $s^{-1}$))', fontsize=15)\n",
    "plt.ylabel('Fvar', fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "legend_labels = ['w/o UL - 4FGL', 'w/ UL - 4FGL', 'w/o UL - Luana', 'w/ UL - Luana']\n",
    "legend_handles = [plt.scatter([], [], color='red', marker='.'), plt.scatter([], [], color='lightgray', marker='.'),\n",
    "                 plt.scatter([], [], color='blue', marker='.'), plt.scatter([], [], color='gray', marker='.')]\n",
    "plt.legend(legend_handles, legend_labels, loc='upper right', fontsize=15)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of Fvar(4FGL) vs average spectrum flux + Fvar(Luana) vs average history flux\n",
    "\n",
    "## 4FGL\n",
    "x1 = average_flux_4FGL_w_UL\n",
    "y1 = catalog_with_fvar['Unc_Frac_Variability'] / catalog_with_fvar['Frac_Variability']\n",
    "\n",
    "## Luana\n",
    "x2 = average_flux_4FGL_w_UL\n",
    "y2 = fvar_Luana_4FGL['Unc_Frac_Variability'] / fvar_Luana_4FGL['Frac_Variability']\n",
    "\n",
    "## Get the color values for the markers based on the Upper_limits column\n",
    "colors1 = ['lightgray' if ul else 'red' for ul in fvar_Luana_4FGL['Upper_limits']]\n",
    "colors2 = ['gray' if ul else 'blue' for ul in fvar_Luana_4FGL['Upper_limits']]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.scatter(x1, y1, marker='.', c=colors1, s=50, label='4FGL')\n",
    "plt.scatter(x2, y2, marker='.', c=colors2, s=50, label='Luana')\n",
    "plt.title('Unc / 4FGL Fvar vs. Average History Flux (Year Cadence)', fontsize=18)\n",
    "plt.xlabel('Average History Flux (Photon Flux (0.1-100 GeV ph $cm^{-2}$ $s^{-1}$))', fontsize=15)\n",
    "plt.ylabel('Unc_Fvar / Fvar', fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "legend_labels = ['w/o UL - 4FGL', 'w/ UL - 4FGL', 'w/o UL - Luana', 'w/ UL - Luana']\n",
    "legend_handles = [plt.scatter([], [], color='red', marker='.'), plt.scatter([], [], color='lightgray', marker='.'),\n",
    "                 plt.scatter([], [], color='blue', marker='.'), plt.scatter([], [], color='gray', marker='.')]\n",
    "plt.legend(legend_handles, legend_labels, loc='upper right', fontsize=15)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f1f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd7bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4adcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da16e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e43d9c-c49b-4d09-a61d-63912c4c53b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9afaf67c-dc7a-497a-bdb8-84558e4d1baf",
   "metadata": {},
   "source": [
    "## Examples Tarek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef071b2d-3007-4d4a-9d04-08dbc1a37059",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_with_flux_history['Flux_History'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0c497-d325-4a00-b874-9927db3e5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_with_flux_history['Unc_Flux_History'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa67e2e-e38c-4289-9e5c-16b8e9b79f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49eb5667-9602-4eed-af8c-c2251aea77a9",
   "metadata": {},
   "source": [
    "Value \"nan\" in the uncertainties means that it is an upper limit point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751d9ed-30ed-4044-b5d7-a1270248227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting flux points and errors\n",
    "\n",
    "## Values that are not upper limits\n",
    "mask = np.invert(np.isnan(catalog_with_flux_history['Unc_Flux_History'][0][:,0]))\n",
    "## Flux points\n",
    "flux = catalog_with_flux_history['Flux_History'][0][mask]\n",
    "## Uncertainties taken from the positive one (seems larger)\n",
    "flux_unc = catalog_with_flux_history['Unc_Flux_History'][0][:,1][mask]\n",
    "\n",
    "## Extracting Upper Limit points\n",
    "ul_mask = np.isnan(catalog_with_flux_history['Unc_Flux_History'][0][:,0])\n",
    "flux_uls = catalog_with_flux_history['Unc_Flux_History'][0][:,1][ul_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f6c75-d356-4d2c-8ddc-e1be98d21bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053347c-ce54-4038-b574-d73ec9a81dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_unc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0c710-a5e5-4d75-91cd-2f56041160c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122647b0-a3c8-416a-8ecd-143736a57284",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_uls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2f496-f5a6-4de0-bbd8-832ee8bc2e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
